<!DOCTYPE html>
<html>

<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/drawing.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <script src="js/imageSelectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>

<body>
  <div id="navbar"></div>
  <div class="center-content page-container">
    <div class="progress" id="loader">
      <div class="indeterminate"></div>
    </div>
    <!-- Webcam -->
    <div style="position: relative" class="margin">
      <video onplay="onPlay(this)" id="inputVideo" autoplay muted></video>
      <canvas id="overlay" />
    </div>
    <!-- Webcam -->
    <!-- Reference image -->
    <div style="position: relative" class="margin">
      <img id="refImg" src="" style="max-width: 800px;" />
      <canvas id="refImgOverlay" class="overlay" />
    </div>
    <!-- Reference image -->
    <div class="row side-by-side">
      <!-- image_selection_control -->
      <div class="row">
        <label>Upload Reference Image:</label>
        <div>
          <input id="refImgUploadInput" type="file" class="bold" onchange="uploadRefImage()" accept=".jpg, .jpeg, .png">
        </div>
      </div>
      <!-- image_selection_control -->
      <!-- face_detector_selection_control -->
      <div id="face_detector_selection_control" class="row input-field" style="margin-right: 20px;">
        <select id="selectFaceDetector">
          <option value="ssd_mobilenetv1">SSD Mobilenet V1</option>
          <option value="tiny_face_detector">Tiny Face Detector</option>
          <option value="mtcnn">MTCNN</option>
        </select>
        <label>Select Face Detector</label>
      </div>
      <!-- face_detector_selection_control -->
      <!-- fps_meter -->
      <div id="fps_meter" class="row side-by-side">
        <div>
          <label for="time">Time:</label>
          <input disabled value="-" id="time" type="text" class="bold">
          <label for="fps">Estimated Fps:</label>
          <input disabled value="-" id="fps" type="text" class="bold">
        </div>
      </div>
      <!-- fps_meter -->
    </div>
    <!-- ssd_mobilenetv1_controls -->
    <span id="ssd_mobilenetv1_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minConfidence">Min Confidence:</label>
          <input disabled value="0.5" id="minConfidence" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinConfidence()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinConfidence()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- ssd_mobilenetv1_controls -->
    <!-- tiny_face_detector_controls -->
    <span id="tiny_face_detector_controls">
      <div class="row side-by-side">
        <div class="row input-field" style="margin-right: 20px;">
          <select id="inputSize">
            <option value="" disabled selected>Input Size:</option>
            <option value="608">608 x 608</option>
            <option value="128">128 x 128</option>
            <option value="160">160 x 160</option>
            <option value="224">224 x 224</option>
            <option value="320">320 x 320</option>
            <option value="416">416 x 416</option>
            <option value="512">512 x 512</option>
            
          </select>
          <label>Input Size</label>
        </div>
        <div class="row">
          <label for="scoreThreshold">Score Threshold:</label>
          <input disabled value="0.5" id="scoreThreshold" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseScoreThreshold()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseScoreThreshold()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- tiny_face_detector_controls -->
    <!-- mtcnn_controls -->
    <span id="mtcnn_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minFaceSize">Minimum Face Size:</label>
          <input disabled value="20" id="minFaceSize" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinFaceSize()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinFaceSize()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- mtcnn_controls -->
</body>
<script>
let faceMatcher = null

var names = []; //tbd: https://ponyfoo.com/articles/es6-reflection-in-depth
// Array.observe event substitute
//http://dealwithjs.io/es6-features-10-use-cases-for-proxy/#basic
// function trackChange(obj, onChange) {
//   const handler = {
//     set(obj, prop, value) {
//       const oldVal = obj[prop];
//       Reflect.set(obj, prop, value);
//       onChange(obj, prop, oldVal, value);
//     },
//     deleteProperty(obj, prop) {
//       const oldVal = obj[prop];
//       Reflect.deleteProperty(obj, prop);
//       onChange(obj, prop, oldVal, undefined);
//     }
//   };
//   return new Proxy(obj, handler);
// }

// const handler = {
//   get: (obj, prop) => {
//     // console.log(prop)
//     if (prop == 'push') {
//       console.log('push')
//     }
//   }
// }

// var names = new Proxy(names, handler);

// names = trackChange(names, (obj, prop, oldVal, newVal) => {
//   // let propFormat = isNaN(parseInt(prop)) ? `.${prop}` : `[${prop}]`;
//   if (prop == 'length' && newVal > oldVal) { //When add
//     console.log(names[newVal-1]);
//   }


// });




async function uploadRefImage(e) {
  const imgFile = $('#refImgUploadInput').get(0).files[0]
  const img = await faceapi.bufferToImage(imgFile)
  $('#refImg').get(0).src = img.src
  updateReferenceImageResults()
}


function getFaceImageUri(className, idx) {
  // return `${className}/${className}${idx}.png`
  return `${className}.jpg`
}

// fetch first image of each class and compute their descriptors
async function createRGAFaceMatcher(numImagesForTraining = 1) {
  console.log("Start training.")
  const maxAvailableImagesPerClass = 5
  numImagesForTraining = Math.min(numImagesForTraining, maxAvailableImagesPerClass)


  const classes = ['prudence', 'ann']
  const labeledFaceDescriptors = await Promise.all(classes.map(
    async className => {
      const descriptors = []
      for (let i = 1; i < (numImagesForTraining + 1); i++) {
        const img = await faceapi.fetchImage(getFaceImageUri(className, i))
        descriptors.push(await faceapi.computeFaceDescriptor(img))
      }

      return new faceapi.LabeledFaceDescriptors(
        className,
        descriptors
      )
    }
  ))

  return new faceapi.FaceMatcher(labeledFaceDescriptors)
}




async function updateReferenceImageResults() {
  const imgEl = $('#refImg').get(0)
  const canvas = $('#refImgOverlay').get(0)


  // create FaceMatcher with automatically assigned labels
  // from the detection results
  // for the reference image
  const fullFaceDescriptions = await faceapi
    .detectAllFaces(imgEl, getFaceDetectorOptions())
    .withFaceLandmarks()
    .withFaceDescriptors()

  if (!fullFaceDescriptions.length) {
    return
  }

  faceMatcher = new faceapi.FaceMatcher(fullFaceDescriptions)

  // resize detection and landmarks in case displayed image is smaller than
  // original size
  resizedResults = resizeCanvasAndResults(imgEl, canvas, fullFaceDescriptions)
  // draw boxes with the corresponding label as text
  const labels = faceMatcher.labeledDescriptors
    .map(ld => ld.label)

  const boxesWithText = resizedResults
    .map(res => res.detection.box)
    .map((box, i) => new faceapi.BoxWithText(box, labels[i]))

  faceapi.drawDetection(canvas, boxesWithText)
}


let forwardTimes = []

function updateTimeStats(timeInMs) {
  forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
  const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
  $('#time').val(`${Math.round(avgTimeInMs)} ms`)
  $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
}


async function updateResults(videoEl) {

  const options = getFaceDetectorOptions()
  // webcam people match
  const results = await faceapi
    .detectAllFaces(videoEl, options)
    .withFaceLandmarks()
    .withFaceDescriptors()


  // if (results.length > 0)
  //   console.log(results.length)

  // Original webcam face detection
  // drawDetections(videoEl, $('#overlay').get(0), [results])

  drawFaceRecognitionResults(results)
}

function drawFaceRecognitionResults(results) {
  if (!faceMatcher) {
    return
  }

  const canvas = $('#overlay').get(0)
  resizedResults = resizeCanvasAndResults($('#inputVideo').get(0), canvas, results)

  // webcam people match
  const boxesWithText = results.map(({ detection, descriptor }) => {
    let face = faceMatcher.findBestMatch(descriptor)
    let name = face.label;
    let confidence = face.distance;
    let des = face.toString();
    //   if (!name.includes("unknown")) {
    //     return 
    //     new faceapi.BoxWithText(detection.box, name)
    //   }

    // Add if new people appears
    if (!names.includes(name)) {
      names.push(name);
      cb(name)
    }

    return new faceapi.BoxWithText(detection.box, des)
  })

  // Delete if some ppl leave
  if (results.length < names.length) {
    names = names.filter(name => { results.includes(name) })
  }

  // console.log(names)

  faceapi.drawDetection(canvas, boxesWithText)

}

async function onPlay() {
  // console.log("onPlay")
  const videoEl = $('#inputVideo').get(0)
  if (videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded() || !faceMatcher)
    return setTimeout(() => onPlay())

  const ts = Date.now();
  updateTimeStats(Date.now() - ts);

  updateResults(videoEl);

  setTimeout(() => onPlay())
}




async function run() {
  console.log("run")
  // load face detection model
  await changeFaceDetector(TINY_FACE_DETECTOR)
  changeInputSize(608)

  //* load face detection, face landmark model and face recognition models
  await faceapi.loadFaceLandmarkModel('/')
  await faceapi.loadFaceRecognitionModel('/')

  // try to access users webcam and stream the images
  // to the video element
  const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
  const videoEl = $('#inputVideo').get(0)
  videoEl.srcObject = stream

  // initialize face matcher with 1 reference descriptor per RGA ppl
  faceMatcher = await createRGAFaceMatcher(1)
  console.log("Training finished.")
}


$(document).ready(function() {
  renderNavBar('#navbar', 'webcam_ppl_match')
  initFaceDetectionControls()
  run()
})
</script>
</body>

</html>